{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60218a6",
   "metadata": {},
   "source": [
    "### Assignment (26th Feb, 2023) [ Regression-1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921434f",
   "metadata": {},
   "source": [
    "#### Name: Abhinav Gupta\n",
    "#### email: abhinavgta18@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e1eb42",
   "metadata": {},
   "source": [
    "**Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29ba21f",
   "metadata": {},
   "source": [
    "Simple linear regression is a type of regression analysis used to model the relationship between two variables - one independent variable (often denoted by x) and one dependent variable (often denoted by y). The goal of simple linear regression is to find the line of best fit that describes the linear relationship between the two variables.\n",
    "\n",
    "The line of best fit is represented by the equation:\n",
    "\n",
    "y = β0 + β1x + ε\n",
    "\n",
    "where y is the dependent variable, x is the independent variable, β0 is the y-intercept (the point where the line intercepts the y-axis), β1 is the slope (the change in y for a one-unit increase in x), and ε is the error term (the difference between the predicted value and the actual value).\n",
    "\n",
    "\n",
    "Multiple linear regression is a type of regression analysis used to model the relationship between a dependent variable (often denoted by y) and two or more independent variables (often denoted by x1, x2, ..., xn). The goal of multiple linear regression is to find the linear equation that best describes the relationship between the dependent variable and the independent variables.\n",
    "\n",
    "The multiple linear regression equation can be written as:\n",
    "\n",
    "y = β0 + β1x1 + β2x2 + ... + βnxn + ε\n",
    "\n",
    "where y is the dependent variable, x1, x2, ..., xn are the independent variables, β0 is the y-intercept, β1, β2, ..., βn are the slopes (the change in y for a one-unit increase in x1, x2, ..., xn, respectively), and ε is the error term\n",
    "\n",
    "Example of simple linear regression: Predicting the sales of ice cream based on temperature.\n",
    "\n",
    "Example of multiple linear regression: Predicting the house price based on variables such as square footage, number of bedrooms, and location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260a9bea",
   "metadata": {},
   "source": [
    "**Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596c9f5",
   "metadata": {},
   "source": [
    "Linear regression assumes that there is a linear relationship between the dependent and independent variables, the errors are normally distributed and have a constant variance, and there is no multicollinearity between the independent variables.\n",
    "\n",
    "To check these assumptions, one can plot the residuals against the predicted values and check for a pattern, plot a histogram of the residuals to check for normal distribution, and calculate the correlation matrix between the independent variables to detect multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f24df",
   "metadata": {},
   "source": [
    "**Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a651aa3d",
   "metadata": {},
   "source": [
    "The intercept (β0) represents the value of the dependent variable when the independent variable is zero. It provides the starting point for the regression line. For example, in a simple linear regression model that predicts the price of a house based on its size, the intercept represents the predicted price of a house with a size of zero (which is not realistic), and the intercept is typically not meaningful in this scenario.\n",
    "\n",
    "The slope coefficient (β1) represents the change in the dependent variable for a one-unit increase in the independent variable. It provides the slope or the steepness of the regression line. In the same example as above, the slope coefficient represents the predicted increase in the price of a house for a one-unit increase in its size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30054f99",
   "metadata": {},
   "source": [
    "**Q4. Explain the concept of gradient descent. How is it used in machine learning?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3013946",
   "metadata": {},
   "source": [
    "Gradient descent is a numerical optimization algorithm used to minimize the cost or loss function of a machine learning model. The goal of gradient descent is to find the values of the model parameters (or weights) that minimize the difference between the predicted output of the model and the actual output of the training data.\n",
    "\n",
    "Gradient descent is used in machine learning to train a wide variety of models, such as linear regression, logistic regression, neural networks, and support vector machines, among others. The algorithm is used to optimize the parameters of the model during the training phase, so that the model can make accurate predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db0f26",
   "metadata": {},
   "source": [
    "**Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d148d6b",
   "metadata": {},
   "source": [
    "In a multiple linear regression model, the dependent variable is still predicted by a linear function of the independent variables, but the function now includes multiple independent variables. The model equation is of the form:\n",
    "\n",
    "y = β0 + β1x1 + β2x2 + ... + βnxn + ε\n",
    "\n",
    "Compared to simple linear regression, which only involves one independent variable, multiple linear regression is more complex and requires more data to estimate the model parameters accurately. However, it also allows for the analysis of more complex relationships between the dependent variable and multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e7ca32",
   "metadata": {},
   "source": [
    "**Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcdb398",
   "metadata": {},
   "source": [
    "Multicollinearity is a common issue in multiple linear regression, which occurs when two or more predictor variables in a regression model are highly correlated with each other\n",
    "\n",
    "Correlation matrix helps to identify if there is a high correlation between two or more independent variables. VIF helps to identify if there is a problem with multicollinearity. VIF measures how much the variance of an estimated regression coefficient is increased due to multicollinearity among the independent variables.\n",
    "\n",
    "Dropping one or more of the highly correlated independent variables from the model.\n",
    "\n",
    "Combining the highly correlated independent variables into a single variable.\n",
    "\n",
    "Using regularization techniques such as ridge regression or LASSO regression, which can help to shrink the coefficients of the highly correlated independent variables towards zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb02cf3",
   "metadata": {},
   "source": [
    "**Q7. Describe the polynomial regression model. How is it different from linear regression?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8599ea",
   "metadata": {},
   "source": [
    "Polynomial regression is a type of regression analysis where the relationship between the dependent variable and the independent variable is modeled as an nth degree polynomial equation. In other words, instead of fitting a straight line to the data (as in linear regression), polynomial regression fits a curve to the data.\n",
    "\n",
    "The polynomial regression equation can be written as:\n",
    "\n",
    "y = β0 + β1x + β2x^2 + ... + βnx^n + ε\n",
    "\n",
    "where y is the dependent variable, x is the independent variable, β0, β1, β2,...,βn are the coefficients of the polynomial equation, ε is the error term, and n is the degree of the polynomial.\n",
    "\n",
    "Compared to linear regression, polynomial regression can model non-linear relationships between the variables. By adding higher degree terms to the equation, the curve can become more complex and better fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7c8e67",
   "metadata": {},
   "source": [
    "**Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc56b1",
   "metadata": {},
   "source": [
    "**Advantages of polynomial regression:**\n",
    "\n",
    "Can model non-linear relationships between variables\n",
    "\n",
    "Can fit the data more accurately than linear regression\n",
    "\n",
    "Can provide better predictions for some types of data\n",
    "\n",
    "\n",
    "**Disadvantages of polynomial regression:**\n",
    "\n",
    "Can overfit the data, especially for higher degree polynomials\n",
    "\n",
    "Can be more complex and difficult to interpret than linear regression\n",
    "\n",
    "Requires more data points to fit higher degree polynomials accurately.\n",
    "\n",
    "\n",
    "Polynomial regression is preferred over linear regression when there is a non-linear relationship between the dependent variable and one or more independent variables. In practical engineering problems, most of the mathematical equation are non-linear, so this can be applied."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
